{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk import tokenize\n",
    "import pandas as pd\n",
    "from os.path import isfile, join, exists\n",
    "from os import listdir, makedirs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_dataset(input_data):\n",
    "    df_final=pd.DataFrame()\n",
    "    for i in range(5):\n",
    "        state = input_data['summaries'][i]['state_name']\n",
    "        txt_file = open('Dataset/StateDocuments/' + state + '.txt',\"r\")\n",
    "        wiki_para = txt_file.read()\n",
    "        sentences = tokenize.sent_tokenize(wiki_para)\n",
    "        summary = input_data['summaries'][i]['sentences']\n",
    "        dic = {}\n",
    "        dic['sentence'] = []\n",
    "        dic['target'] = []\n",
    "        for sent in sentences:\n",
    "            dic['sentence'].append(sent)\n",
    "            if sent in summary:\n",
    "                dic['target'].append(1)\n",
    "            else:\n",
    "                dic['target'].append(0)\n",
    "        temp_df = pd.DataFrame(dic)\n",
    "        df_final = df_final.append(temp_df, ignore_index=True)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_test_dataset(input_data, dest_path):\n",
    "    df_final=pd.DataFrame()\n",
    "    for i in range(5,8):\n",
    "        state = input_data['summaries'][i]['state_name']\n",
    "        txt_file = open('Dataset/StateDocuments/' + state + '.txt',\"r\")\n",
    "        wiki_para = txt_file.read()\n",
    "        sentences = tokenize.sent_tokenize(wiki_para)\n",
    "        summary = input_data['summaries'][i]['sentences']\n",
    "        dic = {}\n",
    "        dic['sentence'] = []\n",
    "        dic['target'] = []\n",
    "        for sent in sentences:\n",
    "            dic['sentence'].append(sent)\n",
    "            if sent in summary:\n",
    "                dic['target'].append(1)\n",
    "            else:\n",
    "                dic['target'].append(0)\n",
    "        temp_df = pd.DataFrame(dic)\n",
    "        temp_df.to_csv(dest_path + '/test/test_set_'+state+'.csv',index=False)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_list=[]\n",
    "my_path = \"Dataset/\"\n",
    "for file in listdir(\"Dataset\"):\n",
    "    dest_path = \"Intent_Dataset/\"\n",
    "    file_name = join(my_path,file)\n",
    "    if isfile(file_name) and file.startswith(\"user\"):\n",
    "        f = open(join(my_path,file))\n",
    "        data = json.load(f)\n",
    "        intent_list.append(data['intent'])\n",
    "        dest_path = dest_path + \"_\".join(re.sub(r'[^\\w\\s]','',data['intent']).split(' ')) + \"/\" + re.sub(r'\\.txt', '',file)\n",
    "        makedirs(dest_path + \"/test\")\n",
    "        df_train = build_train_dataset(data)\n",
    "        df_train.to_csv(dest_path + '/train_set.csv',index=False)\n",
    "        build_test_dataset(data, dest_path)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
